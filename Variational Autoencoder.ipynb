{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(\n",
    "        './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "        './data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64         # number of data points in each batch\n",
    "N_EPOCHS = 10           # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28     # size of each input\n",
    "HIDDEN_DIM = 256        # hidden dimension\n",
    "LATENT_DIM = 120         # latent vector dimension\n",
    "N_CLASSES = 10          # number of classes in the data\n",
    "lr = 1e-3               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2onehot(idx, n=N_CLASSES):\n",
    "\n",
    "    assert idx.shape[1] == 1\n",
    "    assert torch.max(idx).item() < n\n",
    "\n",
    "    onehot = torch.zeros(idx.size(0), n)\n",
    "    onehot.scatter_(1, idx.data, 1)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim + n_classes, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim + n_classes]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        # latent parameters\n",
    "        mean = self.mu(hidden)\n",
    "        # mean is of shape [batch_size, latent_dim]\n",
    "        log_var = self.var(hidden)\n",
    "        # log_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the size of output (in case of MNIST 28 * 28).\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim + n_classes, hidden_dim)\n",
    "        self.hidden_to_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim + num_classes]\n",
    "        x = F.relu(self.latent_to_hidden(x))\n",
    "        # x is of shape [batch_size, hidden_dim]\n",
    "        generated_x = F.sigmoid(self.hidden_to_out(x))\n",
    "        # x is of shape [batch_size, output_dim]\n",
    "\n",
    "        return generated_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, n_classes)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "\n",
    "        # encode\n",
    "        z_mu, z_var = self.encoder(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        z = torch.cat((x_sample, y), dim=1)\n",
    "\n",
    "        # decode\n",
    "        generated_x = self.decoder(z)\n",
    "\n",
    "        return generated_x, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(INPUT_DIM, HIDDEN_DIM, LATENT_DIM, N_CLASSES)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, mean, log_var):\n",
    "    # reconstruction loss\n",
    "    RCL = F.binary_cross_entropy(reconstructed_x, x, size_average=False)\n",
    "    # kl divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return RCL + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # convert y into one-hot encoding\n",
    "        y = idx2onehot(y.view(-1, 1))\n",
    "        y = y.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "        # loss\n",
    "        loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # convert y into one-hot encoding\n",
    "            y = idx2onehot(y.view(-1, 1))\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "            # loss\n",
    "            loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adithyaiyer/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/adithyaiyer/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 162.24, Test Loss: 132.63\n",
      "Epoch 1, Train Loss: 124.18, Test Loss: 116.27\n",
      "Epoch 2, Train Loss: 113.92, Test Loss: 110.36\n",
      "Epoch 3, Train Loss: 109.89, Test Loss: 108.28\n",
      "Epoch 4, Train Loss: 107.68, Test Loss: 106.00\n",
      "Epoch 5, Train Loss: 106.28, Test Loss: 105.17\n",
      "Epoch 6, Train Loss: 105.28, Test Loss: 104.23\n",
      "Epoch 7, Train Loss: 104.54, Test Loss: 103.89\n",
      "Epoch 8, Train Loss: 103.94, Test Loss: 103.04\n",
      "Epoch 9, Train Loss: 103.46, Test Loss: 102.93\n"
     ]
    }
   ],
   "source": [
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "    patience_counter = 0\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "    best_test_loss =0\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# pick randomly 1 class, for which we want to generate the data\n",
    "y = torch.randint(0, N_CLASSES, (1, 1)).to(dtype=torch.long)\n",
    "print(f'Generating a {y.item()}')\n",
    "\n",
    "y = idx2onehot(y).to(device, dtype=z.dtype)\n",
    "z = torch.cat((z, y), dim=1)\n",
    "\n",
    "reconstructed_img = model.decoder(z)\n",
    "img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, False, False,  True,  True, False,  True,\n",
       "         True,  True, False, False,  True,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True],\n",
       "       [False,  True, False,  True,  True,  True, False,  True, False,\n",
       "         True,  True, False, False, False, False,  True, False, False,\n",
       "        False,  True, False,  True, False],\n",
       "       [ True,  True,  True,  True, False,  True, False,  True, False,\n",
       "        False,  True,  True, False,  True, False, False,  True,  True,\n",
       "         True,  True, False, False, False],\n",
       "       [False, False, False,  True,  True, False,  True,  True,  True,\n",
       "        False, False, False,  True,  True, False, False, False,  True,\n",
       "         True, False, False, False,  True],\n",
       "       [False, False, False, False,  True,  True,  True,  True, False,\n",
       "        False, False, False,  True, False,  True,  True,  True, False,\n",
       "        False,  True, False,  True,  True],\n",
       "       [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        False, False,  True,  True, False, False, False,  True, False,\n",
       "         True, False,  True,  True, False],\n",
       "       [False,  True, False, False, False,  True,  True, False, False,\n",
       "         True, False,  True, False,  True,  True, False,  True,  True,\n",
       "        False, False, False, False, False],\n",
       "       [False, False,  True, False, False,  True,  True,  True, False,\n",
       "         True,  True, False,  True, False,  True, False, False,  True,\n",
       "        False,  True, False, False, False],\n",
       "       [False, False, False, False,  True,  True, False, False,  True,\n",
       "        False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        False,  True, False, False,  True],\n",
       "       [False,  True, False, False, False,  True, False,  True,  True,\n",
       "        False,  True, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False],\n",
       "       [ True, False,  True, False, False, False,  True, False,  True,\n",
       "        False, False,  True, False, False,  True, False,  True, False,\n",
       "        False,  True, False,  True,  True],\n",
       "       [ True, False,  True, False, False, False,  True,  True, False,\n",
       "        False, False,  True, False, False,  True, False,  True, False,\n",
       "        False,  True, False, False,  True],\n",
       "       [False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True, False,  True, False,  True, False, False,\n",
       "        False, False, False, False,  True],\n",
       "       [ True, False, False,  True,  True,  True,  True,  True, False,\n",
       "         True,  True, False,  True, False, False, False, False,  True,\n",
       "        False,  True, False, False, False],\n",
       "       [ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True, False],\n",
       "       [ True, False, False,  True, False, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False,  True, False],\n",
       "       [ True, False, False, False, False, False,  True, False,  True,\n",
       "         True, False,  True, False, False, False,  True, False,  True,\n",
       "        False, False,  True,  True, False],\n",
       "       [ True,  True, False, False,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True, False, False, False],\n",
       "       [False,  True,  True, False,  True, False, False,  True,  True,\n",
       "         True,  True, False, False,  True,  True,  True, False, False,\n",
       "         True, False, False,  True,  True],\n",
       "       [False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True, False, False, False,  True, False, False,\n",
       "         True,  True, False, False, False],\n",
       "       [ True,  True, False,  True, False,  True, False, False, False,\n",
       "        False, False, False, False,  True, False,  True, False,  True,\n",
       "        False, False,  True, False, False],\n",
       "       [False, False, False,  True, False, False, False,  True, False,\n",
       "         True, False,  True, False, False, False,  True, False, False,\n",
       "        False, False, False,  True, False],\n",
       "       [ True,  True, False,  True,  True, False,  True, False,  True,\n",
       "        False, False, False,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(np.random.rand(23,23)>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
